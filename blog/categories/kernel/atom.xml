<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: kernel | Learnings]]></title>
  <link href="http://learnwrite.github.io/blog/categories/kernel/atom.xml" rel="self"/>
  <link href="http://learnwrite.github.io/"/>
  <updated>2013-12-09T20:31:56-08:00</updated>
  <id>http://learnwrite.github.io/</id>
  <author>
    <name><![CDATA[Vaibhav Gautam]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Process synchronization in Linux Kernel]]></title>
    <link href="http://learnwrite.github.io/blog/2013/10/07/process-synchronization-in-linux-kernel/"/>
    <updated>2013-10-07T20:56:00-07:00</updated>
    <id>http://learnwrite.github.io/blog/2013/10/07/process-synchronization-in-linux-kernel</id>
    <content type="html"><![CDATA[<ul id="markdown-toc">
  <li><a href="#synchronization-primitives">Synchronization Primitives</a></li>
  <li><a href="#summary-of-synchronization-primitives">Summary of Synchronization Primitives</a></li>
  <li><a href="#per-cpu-variables">Per-CPU variables</a></li>
  <li><a href="#atomic-operations">Atomic Operations</a></li>
  <li><a href="#optimization-barriers--memory-barriers">Optimization Barriers &amp; Memory Barriers</a></li>
  <li><a href="#semaphores">Semaphores</a></li>
  <li><a href="#spin-locks">Spin Locks</a>    <ul>
      <li><a href="#readwrite-spin-locks">Read/Write Spin Locks</a></li>
    </ul>
  </li>
  <li><a href="#seqlocks">SeqLocks</a></li>
  <li><a href="#read-copy-update-rcu">Read Copy Update (RCU)</a></li>
</ul>

<p>As we have discussed earlier about process synchronization, lets discuss about process synchronization primitives offered in Linux Kernel.</p>

<p>This blog is summary of this <a href="https://www.dropbox.com/s/xvo7qdl9iwjco5x/UnderstandingtheLinuxKernelThirdEditionChapter5KernelSynchronizat.pdf" target="-blank">article</a></p>

<h3 id="synchronization-primitives">Synchronization Primitives</h3>

<ol>
  <li>Per-CPU variables</li>
  <li>Atomic Operation</li>
  <li>Memory barrier</li>
  <li>Spin Lock</li>
  <li>Semaphore</li>
  <li>SeqLocks</li>
  <li>Local Interrupt disabling</li>
  <li>Local softirq disabling</li>
  <li>Read-Copy-Update</li>
</ol>

<h3 id="summary-of-synchronization-primitives">Summary of Synchronization Primitives</h3>

<table>
<tr>
<td>Technique</td><td>Description</td><td>Scope</td>
</tr>
<tr>
<td>Per-CPU variables</td><td>Duplicate a data structure among the CPUs</td><td><code class="mygreen">All CPUs</code></td>
</tr>
<tr>
<td>Atomic operation</td><td>Atomic read-modify-write instruction to a counter</td><td><code class="mygreen">All CPUs</code></td>
</tr>
<tr>
<td>Memory barrier</td><td>Avoid instruction reordering</td><td><code class="myyellow">Local CPU</code><code class="mygreen"> or All CPUs</code></td>
</tr>
<tr>
<td>Spin lock</td><td>Lock with busy wait</td><td><code class="mygreen">All CPUs</code></td>
</tr>
<tr>
<td>Semaphore</td><td>Lock with blocking wait (sleep)</td><td><code class="mygreen">All CPUs</code></td>
</tr>
<tr>
<td>Seqlocks</td><td>Lock based on an access counter</td><td><code class="mygreen">All CPUs</code></td>
</tr>
<tr>
<td>Local interrupt disabling</td><td>Forbid interrupt handling on a single CPU</td><td><code class="myyellow">Local CPU</code></td>
</tr>
<tr>
<td>Local softirq disabling</td><td>Forbid deferrable function handling on a single CPU</td><td><code class="myyellow">Local CPU</code></td>
</tr>
<tr>
<td>Read-copy-update (RCU)</td><td>Lock-free access to shared data structures through pointers</td><td><code class="mygreen">All CPUs</code></td>
</tr>
</table>
<p><br /></p>

<h3 id="per-cpu-variables">Per-CPU variables</h3>

<p>The best synchronization technique consists in designing the kernel so as to avoid
the need for synchronization in the first place.</p>

<p><blockquote><p>Basically, a per-CPU variable is an array of data structures, one element per each CPU in the system.</p></blockquote></p>

<p>A CPU should not access the elements of the array corresponding to the other CPUs.</p>

<p><code>Pros</code></p>

<ul>
  <li>Freely read and modify its own element without fear of race conditions.<br /></li>
  <li>It avoids cache line snooping and invalidations, which are costly operations.</li>
</ul>

<p><strong>[Snooping and Invalidations]</strong> Snooping is the process where the individual caches monitor address lines,  for accesses to memory locations that they have cached. When a write operation is observed to a location that a cache has a copy of, the cache controller invalidates its own copy of the snooped memory location.</p>

<p><code>Cons</code></p>

<ul>
  <li>It can only be used when it make sense to <code>logically split</code> the data across the CPUs of the system<br /></li>
  <li>Do not provide <code>protection</code> against access from asynchronous functions such as <code>interrupt handlers and deferrable functions.</code><br /></li>
  <li>Per-CPU variables are variables are prone to <code>race conditions</code> caused by kernel preemption, both in uniprocessor and multiprocessor systems.<br /></li>
</ul>

<p><strong>[Problem]</strong> What would happen if a kernel control path gets the address of its local copy of a per-CPU variable, and then it is preempted and moved to another CPU: the address still refers to the element of the previous CPU.</p>

<p>As a general rule, a kernel control path should access a per-CPU variable with kernel preemption disabled.</p>

<hr style="border-top: 1.5px dotted black" />
<p><br /></p>

<h3 id="atomic-operations">Atomic Operations</h3>

<p><strong>[Problem]</strong> Several assembly language instructions are of type “read-modify-write” i.e. memory location is accessed twice first to read the old value and second time to write a new value</p>

<p><strong>Detailed explanation</strong><br />
Suppose that two kernel control paths running on two CPUs try to “read-modify-write” the same memory location at the same time by executing nonatomic operations.<br />
At first, <code>both CPUs try to read the same location</code>, but the memory arbiter (a hardware circuit that serializes accesses to the RAM chips) steps in to grant access to one of them and delay the other. However, when the first read operation has completed, the delayed CPU reads exactly the same (old) value from the memory location.
<code>Both CPUs then try to write the same (new) value to the memory location</code>; again, the bus memory access is serialized by the memory arbiter, and eventually both write operations succeed. However, the global result is incorrect because both CPUs write the same (new) value. Thus, the two interleaving “read-modify-write” operations act as a single one.</p>

<p><strong>[Solution]</strong> Reason for problem here is that Both CPU’s try to access memory location at the same time. If operation of “read-modify-write” can be made atomic then problem would be solved i.e. Every such <code>operation must be executed in a single instruction without being interrupted</code> in the middle and avoiding accesses to the same memory location by other CPUs.</p>

<ul>
  <li>Read-modify-write assembly language instructions are atomic if no other processor has taken the memory bus after the read and before the write. <code>Memory bus stealing never happens in a uniprocessor system.</code></li>
  <li>For multiprocessor system, Read-modify-write assembly language instructions whose opcode is prefixed by the <strong>Lock byte</strong> (0xf0) are atomic. </li>
  <li>Other processors cannot access the memory location while the locked instruction is being executed.</li>
</ul>

<p>Sample functions: atomic-read(v), atomic-set(v,i), atomic-add(i,v), atomic-sub(i,v) etc…</p>

<hr style="border-top: 1.5px dotted black" />
<p><br /></p>

<h3 id="optimization-barriers--memory-barriers">Optimization Barriers &amp; Memory Barriers</h3>

<p>Compilers optimize the code for efficient usage of CPU time and memory but this optimizations could be disastrous sometimes when dealing with shared data.</p>

<p>It can never be guaranteed that instructions will be performed in the same order in which they appear in source code mainly because reordering by compiler to optimize and CPU executing several instructions in parallel. This might lead to reordering of memory access patterns.</p>

<p>To avoid this behavior we need a synchronization primitive at two levels</p>

<ul>
  <li>Synchronization primitive at Compiler level - Optimization barrier</li>
  <li>Synchronization primitive at CPU level      - Memory barrier</li>
</ul>

<p>In linux <em>barrier()</em> macro acts as an <em>optimization barrier</em>. 
<blockquote><p>Optimization barrier primitive ensures that assembly language instructions of C statements mentioned before <em>barrier()</em> and assembly language instructions of C statements mentioned after, remains in the same sequence.</p></blockquote></p>

<p>But, Optimization barrier cannot control in which fashion instructions will be executed by CPU.</p>

<p>A <em>memory barrier</em> primitive ensures that the operations placed before the primitive are finished before starting the operations placed after the primitive. Read <em>memory barrier</em> act only on instructions that read from memory, while Write <em>memory barriers</em> act only on instructions that write to memory.</p>

<hr style="border-top: 1.5px dotted black" />
<p><br /></p>

<h3 id="semaphores">Semaphores</h3>

<p>Please visit <a href="http://learnwrite.github.io/blog/2013/10/07/process-synchronization-in-os/#semaphores">Semaphore Page</a></p>

<h3 id="spin-locks">Spin Locks</h3>

<p>When a kernel control path must access a shared data structure or enter a critical section it need to acquire a lock.<br />
Spin Locks are a special kind of lock designed to work in a multiprocessor environment. If kernel control path finds Spin Lock <em>Open</em> it acquires the lock and continue execution else it <em>Spin</em> around repeatedly executing tight instruction loop, until the lock is released.</p>

<p>The waiting kernel control path keeps running on the CPU, even if it has nothing to do besides waste time. <code>Kernel preemption is disabled</code> in CR protected by Spin Locks.
Spin locks are usually convenient, because many kernel resources are locked for a <code>fraction of a millisecond only</code>; therefore, it would be far more time-consuming to release the CPU and reacquire it later.<br />
Kernel preemption is still enabled during the busy wait phase, thus a process waiting for a spin lock to be released could be replaced by a higher priority process.</p>

<table>
<tr>
<td>Macro</td><td>Description</td>
</tr>
<tr>
<td>spin-lock-init()</td><td>Set the spin lock to 1 (unlocked)</td>
</tr>
<tr>
<td>spin-lock()</td><td>Cycle until spin lock becomes 1 (unlocked), then set it to 0 (locked)</td>
</tr>
<tr>
<td>spin-unlock()</td><td>Set the spin lock to 1 (unlocked)</td>
</tr>
<tr>
<td>spin-unlock-wait()</td><td>Wait until the spin lock becomes 1 (unlocked)</td>
</tr>
<tr>
<td>spin-is-locked()</td><td>Return 0 if the spin lock is set to 1 (unlocked); 1 otherwise</td>
</tr>
<tr>
<td>spin-trylock()</td><td>Set the spin lock to 0 (locked), and return 1 if the previous value of the lock was 1; 0 otherwise</td>
</tr>
</table>
<p><br /></p>

<p>Spin Lock with kernel preemption</p>

<div><div class="CodeRay">
  <div class="code"><pre><span class="line-numbers"> <a href="#n1" name="n1">1</a></span><span class="regexp"><span class="delimiter">/</span><span class="delimiter">/</span></span><span class="constant">Invokes</span> preempt-disable() to disable kernel preemption.
<span class="line-numbers"> <a href="#n2" name="n2">2</a></span>
<span class="line-numbers"> <a href="#n3" name="n3">3</a></span>; Intel syntax
<span class="line-numbers"> <a href="#n4" name="n4">4</a></span>
<span class="line-numbers"> <a href="#n5" name="n5">5</a></span><span class="key">locked</span>:                      ; <span class="constant">The</span> lock variable. <span class="error">1</span> = locked, <span class="integer">0</span> = unlocked.
<span class="line-numbers"> <a href="#n6" name="n6">6</a></span>dd      <span class="integer">0</span>
<span class="line-numbers"> <a href="#n7" name="n7">7</a></span>
<span class="line-numbers"> <a href="#n8" name="n8">8</a></span>spin-<span class="key">lock</span>:
<span class="line-numbers"> <a href="#n9" name="n9">9</a></span>mov     eax(new), <span class="integer">1</span>     ; <span class="constant">Set</span> the <span class="constant">EAX</span> register to <span class="integer">1</span>.
<span class="line-numbers"><strong><a href="#n10" name="n10">10</a></strong></span>
<span class="line-numbers"><a href="#n11" name="n11">11</a></span>xchg    eax(new), [locked]
<span class="line-numbers"><a href="#n12" name="n12">12</a></span>; <span class="constant">Atomically</span> swap the <span class="constant">EAX</span> register with
<span class="line-numbers"><a href="#n13" name="n13">13</a></span>;  the lock variable.
<span class="line-numbers"><a href="#n14" name="n14">14</a></span>; This will always store <span class="integer">1</span> to the lock, leaving
<span class="line-numbers"><a href="#n15" name="n15">15</a></span>;  previous value <span class="keyword">in</span> the <span class="constant">EAX</span> register.
<span class="line-numbers"><a href="#n16" name="n16">16</a></span>
<span class="line-numbers"><a href="#n17" name="n17">17</a></span>test    eax(new), eax(prev)
<span class="line-numbers"><a href="#n18" name="n18">18</a></span>; <span class="constant">Test</span> <span class="constant">EAX</span> with itself. Among other things, this will
<span class="line-numbers"><a href="#n19" name="n19">19</a></span>;  set the processor<span class="string"><span class="delimiter">'</span><span class="content">s Zero Flag if EAX is 0.</span></span>
<span class="line-numbers"><strong><a href="#n20" name="n20">20</a></strong></span><span class="string"><span class="content">; If EAX is 0, then the lock was unlocked and</span></span>
<span class="line-numbers"><a href="#n21" name="n21">21</a></span><span class="string"><span class="content">;  we just locked it.</span></span>
<span class="line-numbers"><a href="#n22" name="n22">22</a></span><span class="string"><span class="content">; Otherwise, EAX is 1 and we didn</span><span class="delimiter">'</span></span>t acquire the lock.
<span class="line-numbers"><a href="#n23" name="n23">23</a></span>
<span class="line-numbers"><a href="#n24" name="n24">24</a></span>//   <span class="constant">Enable</span> kernel preemption preempt-enable() 
<span class="line-numbers"><a href="#n25" name="n25">25</a></span>
<span class="line-numbers"><a href="#n26" name="n26">26</a></span>jnz     spin-lock       ; <span class="constant">Jump</span> back to the <span class="constant">MOV</span> instruction <span class="keyword">if</span> the <span class="constant">Zero</span> <span class="constant">Flag</span> is
<span class="line-numbers"><a href="#n27" name="n27">27</a></span>;  <span class="keyword">not</span> set; the lock was previously locked, <span class="keyword">and</span> so
<span class="line-numbers"><a href="#n28" name="n28">28</a></span>; we need to spin <span class="keyword">until</span> it becomes unlocked.
<span class="line-numbers"><a href="#n29" name="n29">29</a></span>
<span class="line-numbers"><strong><a href="#n30" name="n30">30</a></strong></span>ret                     ; <span class="constant">The</span> lock has been acquired, <span class="keyword">return</span> to the calling
<span class="line-numbers"><a href="#n31" name="n31">31</a></span>;  function.
<span class="line-numbers"><a href="#n32" name="n32">32</a></span>
<span class="line-numbers"><a href="#n33" name="n33">33</a></span>spin-<span class="key">unlock</span>:
<span class="line-numbers"><a href="#n34" name="n34">34</a></span>mov     eax, <span class="integer">0</span>          ; <span class="constant">Set</span> the <span class="constant">EAX</span> register to <span class="integer">0</span>.
<span class="line-numbers"><a href="#n35" name="n35">35</a></span>
<span class="line-numbers"><a href="#n36" name="n36">36</a></span>xchg    eax, [locked]   ; <span class="constant">Atomically</span> swap the <span class="constant">EAX</span> register with
<span class="line-numbers"><a href="#n37" name="n37">37</a></span>;  the lock variable.
<span class="line-numbers"><a href="#n38" name="n38">38</a></span>
<span class="line-numbers"><a href="#n39" name="n39">39</a></span>ret                     ; <span class="constant">The</span> lock has been released.
</pre></div>
</div>
</div>

<p>In case of kernel preemption, the first step is to disable kernel preemption, preempt-disable()
In the above example <code>Lock is 1 and Unlock is 0</code></p>

<ul>
  <li>In EAX register we push “1” as we wish to acquire lock.<br /></li>
  <li>xchg command will exchange value from EAX register to lock variable but not vice versa. So by step 2, EAX register has value of “1” and lock variable also has value of “1”. This is an atomic operation.<br /></li>
  <li>Step 3, test or validate the current value of lock. If current value of lock(EAX prev) is “1“ i.e. processor zero flag is already set, hence <code>lock is not available.</code> <br /></li>
  <li>Enable kernel preemption and Jump(Spin) back.<br /></li>
  <li>In Step 3, if current value of lock (EAX prev) is “0” then set it with “1” i.e. <code>Lock has been acquired.</code></li>
</ul>

<p>It might happen that process can spin for a long time. If the break-lock field is set then owning process can learn whether there are other processes waiting for the lock. It may decide to release it prematurely to allow other processes.</p>

<h4 id="readwrite-spin-locks">Read/Write Spin Locks</h4>

<p>Read Spin Locks is used to increase the concurrency within kernel. Idea is that allow several kernel control path to access same data structure for “Read” using Read Spin Locks. No kernel control path can modify the data structure using Read Spin Locks. </p>

<p>To modify shared data structure kernel control path needs to acquire Write Spin Locks. Write Spin Lock is granted when no kernel control path have Read Spin Locks.</p>

<p>Reader and Writer Spin Locks have same priority in this case.</p>

<hr style="border-top: 1.5px dotted black" />
<p><br /></p>

<h3 id="seqlocks">SeqLocks</h3>

<p>In Read/Write spin locks reader and write have same priority. Reader must wait until the writer has finished and vice versa.<br />
<blockquote><p>SeqLocks are similar to read/write locks except that they give a much higher priority to writers: in fact a writer is allowed to proceed even when readers are active.</p></blockquote></p>

<p>Writer never waits but reader may be forced to read the data several times until it get valid copy. Each reader must read sequence counter twice i.e. before and after reading the data and then check whether sequence counter values are same. If its not equal then it means that writer must has become active and has increased the sequence counter, thus implicitly telling the reader that the data just read is not valid.</p>

<p>Every time writer acquire and release sequence lock it must increment sequence counter. When counter is odd means writer is in progress and when counter is even means writer is done.<br />
When a reader enters a critical region, it <code>does not need to disable kernel preemption</code>; on the other hand, the <code>writer automatically disables kernel preemption</code> when entering the critical region, because it acquires the spin lock.</p>

<p>SeqLocks must not be used for </p>

<ul>
  <li>The data structure to be protected does not include pointers that are modified by the writers and dereferenced by the readers (otherwise, a writer could change the pointer under the nose of the readers)</li>
  <li>The code in the critical regions of the readers does not have side effects (otherwise, multiple reads would have different effects from a single read)</li>
</ul>

<hr style="border-top: 1.5px dotted black" />
<p><br /></p>

<h3 id="read-copy-update-rcu">Read Copy Update (RCU)</h3>

<p>This technique is designed to <code>protect</code> data structures that are mostly <code>accessed for reading</code> by several CPUs.<br />
The key idea consists of limiting the scope of RCU as follows:</p>

<ol>
  <li>Only data structures that are dynamically allocated and referenced by means of pointers can be protected by RCU.</li>
  <li>No kernel control path can sleep inside a critical region protected by RCU.</li>
</ol>

<p><strong>Writer</strong></p>

<ul>
  <li>When a writer wants to update the data structure, it dereferences the pointer and makes a copy of the whole data structure.<br /></li>
  <li>Next, the writer modifies the copy.<br /></li>
  <li>Once finished, the writer changes the pointer to the data structure so as to make it point to the updated copy.<br /></li>
</ul>

<p>Because <code>changing the value of the pointer is an atomic operation</code>, each reader or writer sees either the old copy or the new one: no corruption in the data structure may occur.</p>

<p>Memory barrier is required to ensure that the updated pointer is seen by the other CPUs only after the data structure has been modified. </p>

<p>Spin lock is coupled with RCU to forbid the concurrent execution of writers.</p>

<p><strong>[Problem]</strong> Old copy of the data structure cannot be freed right away when the writer updates the pointer. In fact, the readers that were accessing the data structure when the writer started its update could still be reading the old copy. The old copy can be freed only after all (potential) readers on the CPUs have executed.</p>
]]></content>
  </entry>
  
</feed>
